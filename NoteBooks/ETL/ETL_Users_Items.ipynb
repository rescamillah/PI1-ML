{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL Australian user items\n",
    "\n",
    "Este Archivo de trabajo, contiene las instrucciones necesarias para ejecutar la extración, transformación y carga del archivo \"australian_users_items.json\".\n",
    "\n",
    "La intención inicial del documento, es mostrar el paso a paso de la extracción de la información, explicar y justificar cada una de las instrucciones ejecutadas para la transformación del archivo y brindar como resultado un archivo limpio en formato CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerías necesarias para trabajar con archivos de tipo json\n",
    "import pandas as pd # Se utiliza pandas para trabajar con dataframes\n",
    "import json # Se utiliza json para la lectura de archivos en este formato\n",
    "import numpy as np # Se utiliza numpy para ciertas operaciones matematicas en los dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo una lectura previa del archivo, utilizando el editor de texto notepad++, podemos notar que el archivo no cumple con la estructura que debe de tener el formato json, es decir, que sus claves y valores, deben de venir especificados con comillas dobles, sin embargo, en el archivo están definidas con comillas simples.\n",
    "\n",
    "Esto provoca que, tengamos que reemplazar estas comillas simples que delimitan las claves y valores, cuidando que no se sistituyan aquellas comillas simples existentes dentro de los valroes de tipo string como lo pueden ser las apostrofes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este apartado, comenzamos con la lectura del archivo json y colocamos su contenido en un dataframe de pandas\n",
    "Ruta_Json = '..\\\\..\\\\Inputs Originales\\\\australian_users_items.json' # Guardamos la ruta del archivo json a leer en una variable\n",
    "\n",
    "# Se prcede a leer el archivo json con la intención de reemplazar las comillas simples\n",
    "with open(Ruta_Json, 'r', encoding='utf-8') as archivo: # Se crea la variable archivo para leer el archivo\n",
    "    contenido = archivo.read() # Se guarda el resultado de lectura del archivo en una variable\n",
    "    # Para la sititución de las comillas simples que rodean a las claves y valores, se hará utilizando ciertos patrones que justo delimitan las claves y valores\n",
    "    contenido = contenido.replace(\"', '\", '\",\"').replace(\"{'\", '{\"').replace(\"': '\", '\": \"').replace(\"':\", '\":').replace(\", '\", ', \"')  # Se aplica la sistitución de los patrones encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este apartado, comenzamos con la lectura del archivo json y colocamos su contenido en un dataframe de pandas\n",
    "Ruta_Json_Editado = '..\\\\..\\\\Inputs Originales\\\\australian_users_items_editado.json' # Guardamos la ruta del archivo json a leer en una variable\n",
    "\n",
    "# Se procede a guardar el archivo editado como un nuevo archivo de tipo json\n",
    "with open(Ruta_Json_Editado, 'w', encoding='utf-8') as archivo: # Se crea el archivo json editado\n",
    "    archivo.write(contenido) # Se vacía el contenido dentro del archivo y se guarda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este apartado, comenzamos con la lectura del archivo json editado y colocamos su contenido en un dataframe de pandas\n",
    "Ruta_Json_Editado = '..\\\\..\\\\Inputs Originales\\\\australian_users_items_editado.json' # Guardamos la ruta del archivo json a leer en una variable\n",
    "\n",
    "# Debido a que en el archivo hay varias líneas que no pueden ser decodificadas, utilizaremos una lista para ignorar la información que muestra error\n",
    "datos_cargados = [] # Se crea una lista de datos cargados\n",
    "\n",
    "# Leemos el archivo de json editado\n",
    "with open(Ruta_Json_Editado, 'r', encoding='utf-8') as archivo: # Se lee el archivo en codificación utf8\n",
    "    for linea in archivo: # Para cada línea existente en el archivo\n",
    "        try: # Se capturan los errores que puedan existir al leer los datos\n",
    "            datos = json.loads(linea) # Se cargan los datos de la línea leida\n",
    "            datos_cargados.append(datos) # Se añade la fila leída a la lista datos\n",
    "        except json.JSONDecodeError as e: # En caso de que exista un error en la carga\n",
    "            continue # Se continua con el siguiente registro\n",
    "\n",
    "# Se convierte el contenido trabajado previamente en un DataFrame\n",
    "df_Users_Items = pd.DataFrame(datos_cargados) # Se asigna el DataFrame resultante'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora que tenemos un Dataframe con la información del archivo, comenzamos a explorar el contenido y realizamos ciertos trabajos de limpieza\n",
    "\n",
    "# Analizamos la estructura y contenido del dataframe\n",
    "df_Users_Items.info() # Nos muestra la información general del dataframe\n",
    "# Por ahora, tenemos un total de 5 columnas de tipo objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haciendo un análisis estadístico del Dataframe, veremos cuántos registros contiene, el total de vacíos y duplicados\n",
    "\n",
    "print(\"Total de filas en el DataFrame: \", df_Users_Items.shape[0]) # Mostramos el total de registros del DataFrame \n",
    "# Se tiene un total de 88,146 registros dentro del archivo\n",
    "print(\"Total de registros vacíos por columna: \", df_Users_Items.isnull().sum()) # Mostramos el total de registros vacíos\n",
    "\n",
    "# Se reemplazan los valores vacíos descritos como 'null', 'None' con NaN en todo el DataFrame\n",
    "df_Users_Items.replace(['', 'null', 'None'], np.nan, inplace=True) # Se guardel resultaddo en el DataFrame\n",
    "# Se procede a eliminar aquellos registros que estén vacíos\n",
    "df_Users_Items.dropna(inplace = True) # Se guarda el resultado en el mismo dataframe\n",
    "print(\"Total de filas en el DataFrame sin registros vacíos: \", df_Users_Items.shape[0]) # Mostramos el total de registros del DataFrame \n",
    "# al no existir registros vacíos, no se elimina nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se nomraliza la columna de \"items\", aplanando sus valores y guardando el resultado en el mismo dataframe\n",
    "df_Users_Items = pd.json_normalize(datos_cargados, record_path=['items'], meta=['steam_id','items_count','user_id','user_url'] ) # Se guarda el resultado en el mismo Dataframe\n",
    "df_Users_Items = df_Users_Items.drop_duplicates(keep='first') # Se liminan duplicados del dataframe\n",
    "df_Users_Items.shape[0] # Después de aplanar el archivo, nos damos cuenta que tenemos 4,935,329 registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a la cantidad de registros del DataFrame, se requiere hacer una limpieza que permita trabajar solo con los registros y columnas eficientes\n",
    "filas_con_cero = (df_Users_Items['playtime_forever'] == 0).sum() # Contamos las filas con valor 0 en la columna 'hours_game'\n",
    "print(f\"Existen {filas_con_cero} filas con valor 0 en la columna 'hours_game'.\") # se imprime el resultado\n",
    "# Notamos que hay un total de 1,751,536 registros vacíos, es decir, un 35% de los registros resultan no ser representativos para nuestros análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Users_Items = df_Users_Items[df_Users_Items['playtime_forever'] != 0] # Se eliminan del dataframe aquellos registros que contengan 0 en la columna playtime_foreves\n",
    "df_Users_Items.shape[0] # Después de eliminar los registros sin juego del archivo, nos quedamos con 3,183,793 registros\n",
    "df_Users_Items = df_Users_Items.drop(['item_name','playtime_2weeks','steam_id','items_count','user_url'], axis=1) # Se procede a eliminar aquellas columnas que no serían útiles para el análisis o que se pueden obtener desde otro csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el resultado de la limpieza en un nuevo archivo de tipo csv\n",
    "df_Users_Items.to_csv('..\\\\..\\\\Archivos Limpios\\\\australian_users_items_limpio.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Por ahora, se ha terminado con la limpieza de la información del archivo users_items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
